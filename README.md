# ğŸ§â€â™€ï¸ Sign-Language-Translator  
**Bridging Silence with Seamless Sign Language Communication**

---

![repo-top-language](https://img.shields.io/github/languages/top/ShaileshKumar7234/Sign-Language-Translator)
![last-commit](https://img.shields.io/github/last-commit/ShaileshKumar7234/Sign-Language-Translator)
![repo-language-count](https://img.shields.io/github/languages/count/ShaileshKumar7234/Sign-Language-Translator)

---

## ğŸ”§ Built With

- ğŸ **Python**
- ğŸ“„ **Markdown**
- ğŸ¤– TensorFlow / Keras
- ğŸ–¼ï¸ OpenCV
- ğŸ–ï¸ MediaPipe
- ğŸ™ï¸ pyttsx3
- ğŸªŸ Tkinter

---

## ğŸ“š Table of Contents

- [ğŸ“Œ Overview](#overview)
- [ğŸš€ Getting Started](#getting-started)
  - [âœ… Prerequisites](#prerequisites)
  - [ğŸ“¦ Installation](#installation)
- [â–¶ï¸ Usage](#usage)
- [ğŸ§ª Testing](#testing)
- [ğŸ“„ License](#license)

---

## ğŸ“Œ Overview

**Sign-Language-Translator** is a powerful developer tool designed to facilitate **real-time American Sign Language (ASL)** interpretation using **computer vision** and **machine learning** techniques.

It provides a complete pipelineâ€”from **data collection and labeling** to **model training** and **live gesture recognition**â€”making sign language **accessible**, **interactive**, and **voice-enabled**.

---

### ğŸ’¡ Why Sign-Language-Translator?

This project streamlines the development of sign language communication systems. The core features include:

- ğŸ§© **Gesture Data Collection**: Capture and label hand landmarks via webcam for dataset creation.  
- ğŸ§  **Model Training & Evaluation**: Build and evaluate neural network classifiers for gesture recognition.  
- ğŸ–¥ï¸ **Real-Time Recognition**: Live hand detection and classification with instant on-screen captions.  
- ğŸ™ï¸ **Voice Output**: Converts recognized gestures into speech using offline text-to-speech.  
- ğŸ› ï¸ **Modular Design**: Clean, scalable, and adaptable to new gestures, datasets, or models.

---

## ğŸš€ Getting Started

### âœ… Prerequisites

This project requires the following:

- Python (â‰¥ 3.8 recommended)
- Conda (Anaconda/Miniconda)
- Webcam

### ğŸ“¦ Installation

#### 1. Clone the repository

```bash
git clone https://github.com/ShaileshKumar7234/Sign-Language-Translator
cd Sign-Language-Translator
```

#### 2. Create a conda environment

```bash
conda env create -f conda.yml
```

> This installs all required packages including TensorFlow, OpenCV, pyttsx3, MediaPipe, and more.

---

## â–¶ï¸ Usage

Activate the environment and run the application:

```bash
conda activate asl_env
python src/gui_app.py
```

This will:

- Open a webcam feed in a GUI window
- Detect hand signs in real-time
- Display the translated letter as a caption
- Speak the letter aloud using TTS

---

## ğŸ§ª Testing

If unit tests are added in the future (using `pytest` or `unittest`), run them like this:

```bash
conda activate asl_env
pytest
```

> ğŸ”§ *Currently, test coverage is under development.*

---

## ğŸ“ Project Structure

```
Sign-Language-Translator/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ asl_model.h5
â”‚   â””â”€â”€ label_map.npy
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ gui_app.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ generate_label_map.py
â”‚   â””â”€â”€ inspect_label_map.py
â”‚
â”œâ”€â”€ data/                # Optional: for training samples
â”œâ”€â”€ conda.yml            # Conda environment file
â””â”€â”€ README.md
```

---

## ğŸ“„ License

This project is open-source and intended for educational, personal, and non-commercial use.  
For commercial applications, please seek prior permission from the author.

---

## ğŸ™‹â€â™‚ï¸ Author

**Shailesh Kumar**  
ğŸ”— GitHub: [@ShaileshKumar7234](https://github.com/ShaileshKumar7234)
